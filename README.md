# Stock Market Analysis & Prediction

A Streamlit app and Jupyter analysis for multi-sector Indian stock data. It ingests historical prices, engineers features with PySpark, and trains tree-based regressors to predict close prices and visualize sector trends.

## Project Structure
- `app.py` — Streamlit UI that trains a PySpark model on uploaded CSV and visualizes predictions
- `Analysis.ipynb` — Notebook for data collection (yfinance), feature engineering (PySpark/Pandas), modeling and visualizations
- `multi_sector_stock_data.csv` — Example dataset generated by the notebook
- `GBT_predictions.csv` — Optional saved predictions (if present)

## Requirements
- Python 3.10+
- Java 8+ runtime (for PySpark)

Python libraries (see `requirements.txt`):
- streamlit, pandas, matplotlib, plotly, seaborn
- pyspark, scikit-learn (if used), yfinance, ipywidgets

## Quickstart

### 1) Create and activate a virtual environment
```bash
python -m venv .venv
.venv\Scripts\activate  # Windows PowerShell
```

### 2) Install dependencies
```bash
pip install -r requirements.txt
```

### 3) Run the Streamlit app
```bash
streamlit run app.py
```
Upload a CSV with columns: `Date, Open, High, Low, Close, Adj Close, Volume, Ticker`. The app will engineer features with PySpark, train a model, and plot Actual vs Predicted prices by ticker and sector.

### 4) Use the notebook
Open `Analysis.ipynb` in Jupyter to download data via yfinance, build features, train models (RandomForest/GBT), and generate plots.

## Data Notes
- Example tickers cover Tech, Auto, Bank, Pharma, and Defense sectors.
- Large datasets may require more memory/compute. Adjust Spark config as needed.

## GitHub
Typical workflow:
```bash
git init
git add .
git commit -m "Initial commit: Streamlit app, analysis notebook, data"
```
